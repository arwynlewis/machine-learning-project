{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e5bbd6",
   "metadata": {},
   "source": [
    "# Data Sources for Final Project\n",
    "\n",
    "Data was collected from the following sources:\n",
    "- Fire detection areas\n",
    "    - NASA Fire Information for Resource Management System: https://firms.modaps.eosdis.nasa.gov/usfs/active_fire/\n",
    "    - Automated retrieval of files in the 2015-2025 time range (code is given below for implementation)\n",
    "- General forest related data\n",
    "    - Global Forest Watch tree cover and fire alert data downloaded from dashboards: https://www.globalforestwatch.org/\n",
    "- Weather data\n",
    "    - Climate Data Store API (code is given below for implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a04b1e",
   "metadata": {},
   "source": [
    "## Fire Detection Areas (FIRMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9edeeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIIRS file missing\n",
      "Final Colorado dataset saved: (84110, 6)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "os.makedirs(\"firms_raw\", exist_ok=True)\n",
    "\n",
    "# Bouding box for Colorado\n",
    "lat_min, lat_max = 36.992426, 41.003444\n",
    "lon_min, lon_max = -109.060253, -102.041524\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# MODIS data (monthly files)\n",
    "# Fire records before VIIRS launch in 2018\n",
    "for year in range(2015, 2018):\n",
    "    for month in range(1, 13):\n",
    "        month_str = f\"{month:02d}\"\n",
    "        filename = f\"modis_{year}_United_States.csv\" \n",
    "        url = f\"https://firms.modaps.eosdis.nasa.gov/data/country/MODIS_C6_1/USA/{year}/{filename}\"\n",
    "        try:\n",
    "            r = requests.get(url)\n",
    "            if r.status_code == 200 and len(r.text) > 100:\n",
    "                df = pd.read_csv(StringIO(r.text))\n",
    "                df.columns = df.columns.str.lower()\n",
    "                if 'acq_date' in df.columns:\n",
    "                    df['acq_date'] = pd.to_datetime(df['acq_date'])\n",
    "                df_co = df[\n",
    "                    (df['latitude'] >= lat_min) & (df['latitude'] <= lat_max) &\n",
    "                    (df['longitude'] >= lon_min) & (df['longitude'] <= lon_max)\n",
    "                ]\n",
    "                all_data.append(df_co)\n",
    "            else:\n",
    "                print(\"No file found\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fetch error {filename}: {e}\")\n",
    "\n",
    "# VIIRS NOAA-20 2018â€“2025 (one file per year)\n",
    "for year in range(2018, 2026):\n",
    "    filename = f\"viirs-jpss1_{year}_United_States.csv\"\n",
    "    url = f\"https://firms.modaps.eosdis.nasa.gov/data/country/VIIRS_NOAA20_NRT/USA/{year}/{filename}\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200 and len(r.text) > 100:\n",
    "            df = pd.read_csv(StringIO(r.text))\n",
    "            df.columns = df.columns.str.lower()\n",
    "            if 'acq_date' in df.columns:\n",
    "                df['acq_date'] = pd.to_datetime(df['acq_date'])\n",
    "            df_co = df[\n",
    "                (df['latitude'] >= lat_min) & (df['latitude'] <= lat_max) &\n",
    "                (df['longitude'] >= lon_min) & (df['longitude'] <= lon_max)\n",
    "            ]\n",
    "            all_data.append(df_co)\n",
    "        else:\n",
    "            print(\"VIIRS file missing\")\n",
    "    except Exception as e:\n",
    "        print(\"Fetch error\")\n",
    "\n",
    "# Combine all\n",
    "if all_data:\n",
    "    df_all = pd.concat(all_data, ignore_index=True)\n",
    "    # Keep only relevant columns\n",
    "    cols_to_keep = [c for c in ['latitude','longitude','acq_date','frp','confidence','daynight'] if c in df_all.columns]\n",
    "    df_all = df_all[cols_to_keep]\n",
    "\n",
    "    # Fix the confidence column type\n",
    "    if 'confidence' in df_all.columns:\n",
    "        df_all = df_all[df_all['confidence'] != 'l']\n",
    "        df_all['confidence'] = df_all['confidence'].astype(str)\n",
    "\n",
    "    # Save to a Parquet\n",
    "    df_all.to_parquet(\"firms_colorado_2015_2025.parquet\", index=False)\n",
    "    print(\"Final Colorado dataset saved:\", df_all.shape)\n",
    "else:\n",
    "    print(\"No data found.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a747d41f",
   "metadata": {},
   "source": [
    "## Global Forest Watch\n",
    "Two `csvs` downloaded from online dashboard. One for treecover loss from fires in the period 2015-2025, and one for any VIIRS alerts during the same time period. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6feeb1",
   "metadata": {},
   "source": [
    "## Climate Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9c5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 16:27:48,872 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-09-08 16:27:49,377 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-09-08 16:27:49,847 INFO Request ID is 40470ad6-4e81-409b-b888-1997ecb7bcb4\n",
      "2025-09-08 16:27:51,011 INFO status has been updated to accepted\n",
      "2025-09-08 16:36:13,419 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4906d48a314848e7ad7814e1fa31c2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cad0674beb219880390648a089128796.grib:   0%|          | 0.00/143M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'cad0674beb219880390648a089128796.grib'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%pip install cdsapi\n",
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "import cdsapi\n",
    "\n",
    "dataset = \"reanalysis-era5-land\"\n",
    "request = {\n",
    "    \"variable\": [\n",
    "        \"soil_temperature_level_1\",\n",
    "        \"snowmelt\",\n",
    "        \"volumetric_soil_water_layer_1\",\n",
    "        \"surface_net_solar_radiation\",\n",
    "        \"leaf_area_index_high_vegetation\"\n",
    "    ],\n",
    "    \"year\": \"2015\",\n",
    "    \"month\": \"08\",\n",
    "    \"day\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\",\n",
    "        \"13\", \"14\", \"15\",\n",
    "        \"16\", \"17\", \"18\",\n",
    "        \"19\", \"20\", \"21\",\n",
    "        \"22\", \"23\", \"24\",\n",
    "        \"25\", \"26\", \"27\",\n",
    "        \"28\", \"29\", \"30\",\n",
    "        \"31\"\n",
    "    ],\n",
    "    \"time\": [\n",
    "        \"00:00\", \"01:00\", \"02:00\",\n",
    "        \"03:00\", \"04:00\", \"05:00\",\n",
    "        \"06:00\", \"07:00\", \"08:00\",\n",
    "        \"09:00\", \"10:00\", \"11:00\",\n",
    "        \"12:00\", \"13:00\", \"14:00\",\n",
    "        \"15:00\", \"16:00\", \"17:00\",\n",
    "        \"18:00\", \"19:00\", \"20:00\",\n",
    "        \"21:00\", \"22:00\", \"23:00\"\n",
    "    ],\n",
    "    \"data_format\": \"grib\",\n",
    "    \"download_format\": \"unarchived\",\n",
    "    \"area\": [41, -109, -36, -102]\n",
    "}\n",
    "\n",
    "client = cdsapi.Client()\n",
    "client.retrieve(dataset, request).download()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DTSC-5501",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
